{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9a2446d",
   "metadata": {},
   "source": [
    "# üì∞ AI News Fetching & Storage Script\n",
    "\n",
    "## üîç Overview:\n",
    "This script fetches AI-related news articles from an API, processes them into a structured format, and stores them in a **SQLite database**. If database storage fails, the data is saved as a **CSV backup**. The script can also be run **periodically**.\n",
    "\n",
    "---\n",
    "\n",
    "## üìå Script Breakdown:\n",
    "\n",
    "### **1Ô∏è‚É£ Fetch News from API**\n",
    "- **Loads API key** securely from a `.env` file.\n",
    "- **Sends a request** to the API to fetch **100 AI-related news articles**.\n",
    "- **Handles API errors** (connection issues, HTTP errors, or invalid API responses).\n",
    "\n",
    "### **2Ô∏è‚É£ Process API Response**\n",
    "- Converts **API JSON response** into a **pandas DataFrame**.\n",
    "- Ensures data is structured with relevant columns.\n",
    "\n",
    "### **3Ô∏è‚É£ Store Data in SQLite Database**\n",
    "- **Creates a table** if it doesn't exist.\n",
    "- **Inserts new news articles** into the database.\n",
    "- **Uses transactions** to ensure data consistency.\n",
    "- If database write **fails**, **backs up data as CSV**.\n",
    "\n",
    "### **4Ô∏è‚É£ Run Periodically (Optional)**\n",
    "- Can **run once** or **repeat automatically** every **X seconds**.\n",
    "- Uses **cron (Linux/MacOS)** or **Task Scheduler (Windows)** for scheduling.\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Key Takeaways:\n",
    "‚úÖ **Automates news collection** from an external source.  \n",
    "‚úÖ **Ensures secure API access** using `.env` variables.  \n",
    "‚úÖ **Stores data in a database**, with **CSV backup** for reliability.  \n",
    "‚úÖ **Can run on a schedule** for continuous updates.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6e98540",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63e9609da5a07305d5bfefeafda6cff1\n",
      "[2025-02-09 17:35:48] Collecting news...\n",
      "[2025-02-09 17:35:48] News collected, processing...\n",
      "[2025-02-09 17:35:48] Saving into the database...\n",
      "[2025-02-09 17:35:49] News saved successfully\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "# Necessary variables\n",
    "DB_FILE=\"news.db\"\n",
    "BASE_URL=\"http://api.mediastack.com/v1\"\n",
    "\n",
    "# Imports\n",
    "import pandas as pd # to work with tabular data\n",
    "import sqlite3 # to work with the SQLite database\n",
    "import requests # to make API request\n",
    "import json # to parse json response from API\n",
    "import os\n",
    "from dotenv import load_dotenv # to read environment variable\n",
    "from time import sleep # to run periodically\n",
    "from datetime import datetime\n",
    "\n",
    "# Attributes of a news article as per API specs - all of them will be stored\n",
    "columns = ['author', 'title', 'description', 'url', 'source', 'image', 'category', 'language', 'country', 'published_at']\n",
    "\n",
    "# Function to return current time for basic logging\n",
    "def curr_time():\n",
    "\treturn datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "# Fetch news from API\n",
    "def fetch():\n",
    "\t# Load environment variables from the .env file\n",
    "\tload_dotenv()\n",
    "\t# Read API token from environment\n",
    "\tAPI_KEY = os.getenv(\"API_KEY\")\n",
    "\tprint(API_KEY)\n",
    "\t# Searching ai-related news with \"ai\" as keyword\n",
    "\t# Fetching num_articles (limit) latest (sort) articles\n",
    "\tnum_articles = 100\n",
    "\turl = f\"{BASE_URL}/news?access_key={API_KEY}&languages=en&keywords=ai&sort=published_desc&limit={num_articles}\" # building the URL\n",
    "\tprint(f\"[{curr_time()}] Collecting news...\")\n",
    "\ttry:\n",
    "\t\tresponse = requests.get(url) # Sending actual HTTP request\n",
    "\t\tresult = response.json() # Parsing the response\n",
    "\texcept requests.exceptions.RequestException as e:\n",
    "\t\t# Handle connection problems\n",
    "\t\tprint(f\"[{curr_time()}] API request failed: connection error\")\n",
    "\t\traise SystemExit(e)\n",
    "\n",
    "\t# Check if HTTP request is successful\n",
    "\tif response.status_code != 200:\n",
    "\t\tprint(f\"[{curr_time()}] API request failed: HTTP error\")\n",
    "\t\traise SystemExit(f\"Error {response.status_code}: {response.reason}\")\n",
    "\n",
    "\t# Check if the API server could return meaningful data\n",
    "\tif \"error\" in result:\n",
    "\t\tprint(f\"[{curr_time()}] API request failed: API server returned an error: {result['error']['message']}\")\n",
    "\t\traise SystemExit(result[\"error\"])\n",
    "\n",
    "\tprint(f\"[{curr_time()}] News collected, processing...\")\n",
    "\treturn result\n",
    "\n",
    "# Store the results in a tabular form in a pandas dataframe\n",
    "# Using pandas might be an overkill, but:\n",
    "# 1) provides extensibility if some pre-processing will be needed before inserting\n",
    "# 2) takes care of escaping and proper data insertion\n",
    "def process(result):\n",
    "\t# Creating a dataframe from a list of dicts (see API specs)\n",
    "\tdf = pd.DataFrame.from_records(result[\"data\"], columns=columns)\n",
    "\treturn df\n",
    "\n",
    "def store(df):\n",
    "\t# Store the data in a SQLite database - a lightweight SQL database\n",
    "\tconn = sqlite3.connect(DB_FILE)\n",
    "\n",
    "\t# If the table \"news\" does not yet exist in the database or the database file does not exist, \n",
    "\t# it will be created. Otherwise, no changes will occur\n",
    "\t# N.B. In larger projects this should be done using migrations\n",
    "\n",
    "\t# Stepwise building a query to create the table\n",
    "\tquery_columns = \", \".join([f\"{c} TEXT\" for c in columns])\n",
    "\tcreate_db_query = f\" CREATE TABLE IF NOT EXISTS news ({query_columns})\"\n",
    "\n",
    "\t# Actually creating the table\n",
    "\tconn.execute(create_db_query)\n",
    "\n",
    "\t# Writing the fetched news into the database\n",
    "\t# Using transactions to ensure data consistency\n",
    "\tprint(f\"[{curr_time()}] Saving into the database...\")\n",
    "\tconn.execute('BEGIN') # begin a transaction\n",
    "\ttry:\n",
    "\t\tdf.to_sql('news', con=conn, if_exists=\"append\", index=False)\n",
    "\t\tconn.commit() # commit a transaction\n",
    "\t\tprint(f\"[{curr_time()}] News saved successfully\")\n",
    "\texcept Exception as e:\n",
    "\t\tprint(e)\n",
    "\t\tprint(f\"[{curr_time()}] Failed to save the news to the database, saving to CSV...\")\n",
    "\t\tconn.rollback() # undo the entire transaction in case of an error\n",
    "\t\tdf.to_csv(f\"news_{datetime.now().strftime('%Y_%m_%d')}.csv\", index=False)\n",
    "\t\tprint(f\"[{curr_time()}] News saved to CSV\")\n",
    "\tfinally:\n",
    "\t\tconn.close() # close the DB connection after writing the data\n",
    "\n",
    "def main():\n",
    "\tresult = fetch()\n",
    "\tdf = process(result)\n",
    "\tstore(df)\n",
    "\n",
    "def run_periodically(interval_seconds):\n",
    "\twhile True:\n",
    "\t\ttry:\n",
    "\t\t\tmain()\n",
    "\t\texcept SystemExit as e:\n",
    "\t\t\tprint(f'[{curr_time()}] Error: \"{e}\". Repeating in {interval_seconds} seconds')\n",
    "\t\tfinally:\n",
    "\t\t\tsleep(interval_seconds)\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "\tmain()\n",
    "\t# To run periodically, the proper method would be\n",
    "\t# to set up a cron job (Linux/MacOS) or use\n",
    "\t# Task Scheduler (Windows)\n",
    "\t# However, a simple alternative would be to use\n",
    "\t# run_periodically(n), e.g. with n=24*60*60\n",
    "\t# to run the script once a day\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "712f6470",
   "metadata": {},
   "source": [
    "# üóÑÔ∏è Checking Tables in SQLite Database\n",
    "\n",
    "## üîç Overview:\n",
    "This script connects to an **SQLite database** and retrieves the list of available tables.\n",
    "\n",
    "---\n",
    "\n",
    "## üìå Script Breakdown:\n",
    "\n",
    "### **1Ô∏è‚É£ Define Database Path**\n",
    "- Specifies the **full path** to the SQLite database (`news.db`).\n",
    "\n",
    "### **2Ô∏è‚É£ Connect to Database**\n",
    "- Establishes a **connection** to the database.\n",
    "- Creates a **cursor** to execute SQL queries.\n",
    "\n",
    "### **3Ô∏è‚É£ Fetch Table Names**\n",
    "- Queries SQLite's **system metadata** (`sqlite_master`) to get a list of **all tables**.\n",
    "- Prints the **available tables** in the database.\n",
    "\n",
    "### **4Ô∏è‚É£ Close Connection**\n",
    "- Ensures the **database connection is closed** after execution.\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Key Takeaways:\n",
    "‚úÖ **Verifies database connectivity** before executing queries.  \n",
    "‚úÖ **Lists all tables** to confirm database structure.  \n",
    "‚úÖ **Prepares for further queries** (e.g., retrieving stored news articles).  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99b1d050",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tables in the database: [('news',)]\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "\n",
    "# Define the database path\n",
    "db_path = r\"C:\\Users\\bryan\\Desktop\\RavenPack\\news.db\"\n",
    "\n",
    "# Connect to SQLite\n",
    "conn = sqlite3.connect(db_path)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Check available tables\n",
    "cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "tables = cursor.fetchall()\n",
    "\n",
    "# Print the tables found\n",
    "print(\"Tables in the database:\", tables)\n",
    "\n",
    "# Close connection\n",
    "conn.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f598db",
   "metadata": {},
   "source": [
    "# üì∞ Fetching News Data from SQLite Database\n",
    "\n",
    "## üîç Overview:\n",
    "This script **connects to an SQLite database** and retrieves the **first 5 rows** from the `news` table.\n",
    "\n",
    "---\n",
    "\n",
    "## üìå Script Breakdown:\n",
    "\n",
    "### **1Ô∏è‚É£ Define Database Path**\n",
    "- Specifies the **file path** to the SQLite database (`news.db`).\n",
    "\n",
    "### **2Ô∏è‚É£ Connect to SQLite**\n",
    "- Establishes a connection to the **SQLite database**.\n",
    "- Allows executing **SQL queries** using `pandas`.\n",
    "\n",
    "### **3Ô∏è‚É£ Retrieve Data**\n",
    "- Runs an **SQL query** to select **the first 5 rows** from the `news` table.\n",
    "- Stores the result in a **pandas DataFrame**.\n",
    "\n",
    "### **4Ô∏è‚É£ Close Connection**\n",
    "- Ensures the **database connection is closed** after retrieving data.\n",
    "\n",
    "### **5Ô∏è‚É£ Display Results**\n",
    "- Prints the retrieved **news data**.\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Key Takeaways:\n",
    "‚úÖ **Confirms data exists** in the database.  \n",
    "‚úÖ **Uses SQL & pandas** for efficient data handling.  \n",
    "‚úÖ **Prepares for further analysis** or visualisation.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13cb3a70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             author                                              title  \\\n",
      "0     Romain Dillet  Investments in French AI ecosystem reach $85B ...   \n",
      "1   Alexander Brown  The Scottish politician who cost taxpayer ¬£100...   \n",
      "2              None                          How to read burnt scrolls   \n",
      "3  Kentigern Minggu  Sarawak‚Äôs Land and Survey to embrace digital t...   \n",
      "4              None  Meta's AI Capex Can Surge +$65B In 2025 - That...   \n",
      "\n",
      "                                         description  \\\n",
      "0  Canadian investment firm Brookfield plans to i...   \n",
      "1  There were also accusations some of the questi...   \n",
      "2  How AI can decipher the writing in a charred p...   \n",
      "3  KUCHING (Feb 9): The Sarawak Land and Survey D...   \n",
      "4  Meta's AI Capex Can Surge +$65B In 2025 - That...   \n",
      "\n",
      "                                                 url         source  \\\n",
      "0  https://techcrunch.com/2025/02/09/investments-...     TechCrunch   \n",
      "1  https://www.scotsman.com/news/politics/the-sco...       scotsman   \n",
      "2  https://www.thehindubusinessline.com/business-...  Business Line   \n",
      "3  https://www.theborneopost.com/2025/02/09/saraw...  theborneopost   \n",
      "4  https://seekingalpha.com/article/4756447-metas...  Seeking Alpha   \n",
      "\n",
      "                                               image    category language  \\\n",
      "0                                               None  technology       en   \n",
      "1  https://www.scotsman.com/jpim-static/image/202...     general       en   \n",
      "2  https://bl-i.thgim.com/public/incoming/3if0uf/...    business       en   \n",
      "3                                               None     general       en   \n",
      "4                                               None     general       en   \n",
      "\n",
      "  country               published_at  \n",
      "0      us  2025-02-09T15:06:32+00:00  \n",
      "1      us  2025-02-09T14:56:54+00:00  \n",
      "2      us  2025-02-09T14:56:11+00:00  \n",
      "3      us  2025-02-09T14:44:18+00:00  \n",
      "4      us  2025-02-09T14:37:56+00:00  \n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "# Define the path to your database file\n",
    "db_path = r\"C:\\Users\\bryan\\Desktop\\RavenPack\\news.db\"\n",
    "\n",
    "# Connect to the SQLite database\n",
    "conn = sqlite3.connect(db_path)\n",
    "\n",
    "# Query to select the first 5 rows from the 'news' table\n",
    "query = \"SELECT * FROM news LIMIT 5\"\n",
    "df = pd.read_sql(query, conn)\n",
    "\n",
    "# Close the database connection\n",
    "conn.close()\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
